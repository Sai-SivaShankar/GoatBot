{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U discord.py\n",
        "!pip install langchain\n",
        "!pip install -qU langchain-groq\n",
        "!pip install python-dotenv\n",
        "!pip install nest_asyncio\n",
        "!pip install youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG7I_JGCwedD",
        "outputId": "1a68453a-d50f-4de5-d52a-e4a187209d0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting discord.py\n",
            "  Downloading discord.py-2.4.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from discord.py) (3.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4,>=3.7.4->discord.py) (3.8)\n",
            "Downloading discord.py-2.4.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: discord.py\n",
            "Successfully installed discord.py-2.4.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.38 (from langchain)\n",
            "  Downloading langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.117-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.38->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.38-py3-none-any.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.117-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, jsonpatch, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.16 langchain-core-0.2.38 langchain-text-splitters-0.2.4 langsmith-0.1.117 orjson-3.10.7 tenacity-8.5.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.8.30)\n",
            "Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import discord\n",
        "from discord.ext import commands,tasks\n",
        "from discord import File\n",
        "import asyncio\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from googleapiclient.discovery import build"
      ],
      "metadata": {
        "id": "BSHpOD3mp4YZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
      ],
      "metadata": {
        "id": "sw7SKjMZ2tEM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the .env file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Install python-dotenv package\n",
        "!pip install python-dotenv\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv('myenv.env')\n",
        "\n",
        "# Access the API keys\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
        "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
        "os.environ['YOUTUBE_API_KEY'] = os.getenv('YOUTUBE_API_KEY')\n",
        "BOT_TOKEN = \"ENTER YOUR BOT TOKEN\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "s3lTZPIW3HRD",
        "outputId": "47d61494-81f3-493a-871a-dc1cb84797ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bf9af789-e971-48aa-8f8f-257da4b0af3b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bf9af789-e971-48aa-8f8f-257da4b0af3b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving myenv.env to myenv.env\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(model='llama3-8b-8192')"
      ],
      "metadata": {
        "id": "ClK4F-94CWJA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YouTubeSummarizer:\n",
        "    def __init__(self, custom_url, discord_channel_name):\n",
        "        self.custom_url = custom_url\n",
        "        self.discord_channel_name = discord_channel_name\n",
        "        self.youtube = build('youtube', 'v3', developerKey=os.environ['YOUTUBE_API_KEY'])\n",
        "        self.llm = llm\n",
        "        self.transcript_summary_prompt = PromptTemplate(\n",
        "            input_variables=[\"transcript\"],\n",
        "            template=\"\"\"\n",
        "            Summarize the following transcript into concise bullet points:\n",
        "\n",
        "            {transcript}\n",
        "\n",
        "            Summary:\n",
        "            -\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    def get_channel_id_from_custom_url(self):\n",
        "        request = self.youtube.search().list(\n",
        "            part='snippet',\n",
        "            q=self.custom_url,\n",
        "            type='channel'\n",
        "        )\n",
        "        response = request.execute()\n",
        "        channel_id = response['items'][0]['snippet']['channelId']\n",
        "        return channel_id\n",
        "\n",
        "    def get_latest_video_id(self, channel_id):\n",
        "        request = self.youtube.search().list(\n",
        "            part='snippet',\n",
        "            channelId=channel_id,\n",
        "            maxResults=1,\n",
        "            order='date'\n",
        "        )\n",
        "        response = request.execute()\n",
        "        latest_video_id = response['items'][0]['id']['videoId']\n",
        "        return latest_video_id\n",
        "\n",
        "    def fetch_transcript(self, video_id):\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        full_transcript = \" \".join([entry['text'] for entry in transcript])\n",
        "        return full_transcript\n",
        "\n",
        "    async def summarize_transcript(self, transcript):\n",
        "        summary = self.transcript_summary_prompt | self.llm | StrOutputParser()\n",
        "        summary_text = summary.invoke({\"transcript\": transcript})\n",
        "        return summary_text\n",
        "\n",
        "    async def post_summary_to_discord(self, summary, bot):\n",
        "        for guild in bot.guilds:\n",
        "            for channel in guild.text_channels:\n",
        "                if channel.name == self.discord_channel_name:\n",
        "                    await channel.send(summary)\n",
        "                    break\n",
        "\n",
        "    async def summarize_latest_video(self, bot):\n",
        "        channel_id = self.get_channel_id_from_custom_url()\n",
        "        latest_video_id = self.get_latest_video_id(channel_id)\n",
        "        transcript = self.fetch_transcript(latest_video_id)\n",
        "        summary = await self.summarize_transcript(transcript)\n",
        "        await self.post_summary_to_discord(summary, bot)\n",
        "\n",
        "    async def periodic_summarization(self, bot, interval):\n",
        "        while True:\n",
        "            await self.summarize_latest_video(bot)\n",
        "            await asyncio.sleep(interval)"
      ],
      "metadata": {
        "id": "z_SyzfIJqKMn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModerationChain():\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.llm = ChatGroq(model=\"llama3-8b-8192\")\n",
        "\n",
        "    def process(self, message_content: str) -> bool:\n",
        "\n",
        "        goat_prompt = PromptTemplate(\n",
        "            input_variables=[\"message_content\"],\n",
        "            template=\"\"\"\n",
        "            You are an avid Lionel Messi fan. Analyze the following message and determine the tone of the message.\n",
        "            If the tone of the message includes criticism, vulgarity, racial slurs, or mockery towards Lionel Messi,\n",
        "            return \"1\". Otherwise, return \"0\". If the context of the message is unclear or inconclusive, return \"0\".\n",
        "            If the message is too short to understand the context, return \"0\". if the message is not in english, return \"0\".\n",
        "\n",
        "            Message: {message_content}\n",
        "\n",
        "            Your output should be in the following format:\n",
        "            0 or 1\n",
        "\n",
        "            VERY IMPORTANT: This format should be stricly followed. No other text or explanation is allowed. DONOT add any other text or explanation. If the message is not in english, return \"0\".\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        parser = StrOutputParser()\n",
        "        chain = goat_prompt | self.llm | parser\n",
        "\n",
        "        answer = chain.invoke({\"message_content\": message_content})\n",
        "\n",
        "        # Ensure the output is either \"0\" or \"1\"\n",
        "        try:\n",
        "            result = int(answer.strip())\n",
        "            if result not in [0, 1]:\n",
        "                raise ValueError(\"Output not 0 or 1\")\n",
        "        except ValueError:\n",
        "            result = int(0)  # Default to not deleting the message if the output is unexpected\n",
        "\n",
        "        return answer\n"
      ],
      "metadata": {
        "id": "OxAiF7xY2A7N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = discord.Intents.default()\n",
        "intents.messages = True\n",
        "intents.message_content = True  # This line is necessary to access message content\n",
        "\n",
        "bot = commands.Bot(command_prefix='#', intents=intents)"
      ],
      "metadata": {
        "id": "C6IHPzJLhXPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f273b866-79a6-4d0b-99a6-8cb7cbd83a1c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:discord.client:PyNaCl is not installed, voice will NOT be supported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quote_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Give a Real quote about Lionel Messi, said by football legends. Make sure that the quote is in english and is not fake.\n",
        "\n",
        "    your output should be in the following format:\n",
        "    'They tell me that all men are equal in God’s eyes, this player makes you seriously think about those words.' - soccer commentator Ray Hudson\n",
        "\n",
        "    dont deviate from this format. DONOT write Here's a real quote about Lionel Messi, said by a football legend: or anything else at the beginning.\n",
        "    \"\"\",\n",
        "    )\n",
        "\n",
        "youtube_summarizer = YouTubeSummarizer(custom_url=\"FabrizioRomanoYT\", discord_channel_name=\"football\")\n",
        "\n",
        "@bot.event\n",
        "async def on_ready():\n",
        "    print(f'Logged in as {bot.user}')\n",
        "\n",
        "    image_url = \"https://fifpro.org/media/fhmfhvkx/messi-world-cup.jpg?rxy=0.48356841796117644,0.31512414378031967&width=1000&height=640&rnd=133210253587130000\"\n",
        "    quote = quote_prompt | llm | StrOutputParser()\n",
        "    # Create an embed with the image and quote\n",
        "    quote_text = quote.invoke({})\n",
        "    embed = discord.Embed(description=quote_text)\n",
        "    embed.set_image(url=image_url)\n",
        "    # Send the embed to the 'general' channel\n",
        "    for guild in bot.guilds:\n",
        "        for channel in guild.text_channels:\n",
        "            if channel.name == 'general':\n",
        "                await channel.send(embed=embed)\n",
        "                break\n",
        "\n",
        "    bot.loop.create_task(youtube_summarizer.periodic_summarization(bot, 3 * 60 * 60))\n"
      ],
      "metadata": {
        "id": "BLkMEsaawJzS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LangChain chain\n",
        "mod = ModerationChain()\n",
        "@bot.command()\n",
        "async def delete(ctx, message_id: int):\n",
        "    try:\n",
        "        message = await ctx.channel.fetch_message(message_id)\n",
        "        await message.delete()\n",
        "        await ctx.send(f'Message {message_id} deleted.')\n",
        "    except discord.NotFound:\n",
        "        await ctx.send(f'Message {message_id} not found.')\n",
        "    except discord.Forbidden:\n",
        "        await ctx.send('I do not have permission to delete messages.')\n",
        "    except discord.HTTPException as e:\n",
        "        await ctx.send(f'Failed to delete message: {e}')\n",
        "\n",
        "@bot.event\n",
        "async def on_message(message):\n",
        "    if message.author == bot.user:\n",
        "        return\n",
        "\n",
        "    if isinstance(message.channel, discord.DMChannel):\n",
        "        return  # Ignore messages from DMs\n",
        "    # Use the LangChain chain to decide whether to delete the message\n",
        "    should_delete = mod.process(message.content)\n",
        "\n",
        "    if should_delete == '1':\n",
        "        await message.delete()\n",
        "        await message.channel.send(f'Message deleted because messi is GOAT.')\n",
        "\n",
        "    await bot.process_commands(message)"
      ],
      "metadata": {
        "id": "Q4XWUJA1hjvx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep track of scores\n",
        "user_scores = {}\n",
        "\n",
        "# Track questions to avoid repetition\n",
        "asked_questions = set()\n",
        "\n",
        "# Function to generate a quiz question\n",
        "async def generate_question():\n",
        "    topic = \"Lionel Messi\"\n",
        "    while True:\n",
        "        prompt = f\"Generate a random question about {topic}.\"\n",
        "        question = llm.invoke(prompt)\n",
        "        question = question.content.strip()\n",
        "        if question not in asked_questions:\n",
        "            asked_questions.add(question)\n",
        "            return question\n",
        "\n",
        "# Function to verify the answer\n",
        "async def verify_answer(question, user_answer):\n",
        "    prompt = (\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"User Answer: {user_answer}\\n\"\n",
        "        \"Please respond with 'Correct' or 'Incorrect'. \"\n",
        "        \"Then, on a new line, provide the correct answer in the format: Correct answer: <answer>.\"\n",
        "    )\n",
        "    feedback = llm.invoke(prompt).content.strip()\n",
        "\n",
        "    # Extract whether the answer is correct and the correct answer\n",
        "    is_correct = \"Correct\" in feedback.split('\\n')[0]\n",
        "    correct_answer = feedback.split(\"Correct answer: \")[-1].strip()  # Assuming the model provides this format\n",
        "\n",
        "    return is_correct, correct_answer\n",
        "\n",
        "@bot.command()\n",
        "async def quiz(ctx):\n",
        "    user = ctx.author\n",
        "    score = user_scores.get(user, 0)\n",
        "\n",
        "    # Start the quiz session with 5 questions\n",
        "    for i in range(5):\n",
        "        question = await generate_question()\n",
        "        await ctx.send(f\"Question {i + 1}: {question}\\nYou have 15 seconds to answer!\")\n",
        "\n",
        "        def check(m):\n",
        "            return m.author == user and m.channel == ctx.channel\n",
        "\n",
        "        try:\n",
        "            # Wait for user's response with a 15-second timeout\n",
        "            msg = await bot.wait_for('message', timeout=15.0, check=check)\n",
        "\n",
        "            # Verify the answer\n",
        "            is_correct = await verify_answer(question, msg.content)\n",
        "            if is_correct:\n",
        "                score += 1\n",
        "                await ctx.send(f\"Correct! Your score is now {score}.\")\n",
        "            else:\n",
        "                await ctx.send(f\"Incorrect. Your score remains {score}.\")\n",
        "        except asyncio.TimeoutError:\n",
        "            await ctx.send(f\"Time's up! The correct answer was not provided.\")\n",
        "\n",
        "    # Update the user's score\n",
        "    user_scores[user] = score\n",
        "\n",
        "    # Send the final score after 5 questions\n",
        "    await ctx.send(f\"Quiz complete! Your final score is {score} out of 5.\")\n",
        "\n",
        "@bot.command()\n",
        "async def leaderboard(ctx):\n",
        "    if user_scores:\n",
        "        leaderboard = sorted(user_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        leaderboard_message = \"Leaderboard:\\n\"\n",
        "        for i, (user, score) in enumerate(leaderboard, start=1):\n",
        "            leaderboard_message += f\"{i}. {user.display_name}: {score} points\\n\"\n",
        "        await ctx.send(leaderboard_message)\n",
        "    else:\n",
        "        await ctx.send(\"No scores yet! Start a quiz with #quiz.\")"
      ],
      "metadata": {
        "id": "_nCxHuBsl-Hm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "if __name__ == \"__main__\":\n",
        "    bot.run(BOT_TOKEN)\n",
        "else:\n",
        "    # In an interactive environment, use a different method to run the bot\n",
        "    async def run_bot():\n",
        "        await bot.start(BOT_TOKEN)\n",
        "\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.create_task(run_bot())\n",
        "    loop.run_forever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FtI7If_Lo5D",
        "outputId": "8bb30d2d-10be-4410-c46c-1c0923f1d2d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[30;1m2024-09-10 15:21:49\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "INFO:discord.client:logging in using static token\n",
            "\u001b[30;1m2024-09-10 15:21:49\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: c9aab56b39c794c3cb5fe28eba57d672).\n",
            "INFO:discord.gateway:Shard ID None has connected to Gateway (Session ID: c9aab56b39c794c3cb5fe28eba57d672).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as GOATbot#3293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PS8WJqwWAx_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SW_F2krrAyYa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}